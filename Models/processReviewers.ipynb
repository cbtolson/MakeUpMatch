{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import mysql.connector\n",
    "from textblob import TextBlob\n",
    "from scipy.spatial.distance import cosine\n",
    "from TrainTest import TrainTest\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "import csv\n",
    "import scipy.sparse as sp\n",
    "from scipy.sparse.linalg import svds\n",
    "pd.options.mode.chained_assignment = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#connect to mysql\n",
    "cnx = mysql.connector.connect(host='152.19.68.141', user='ctolson', password='ilaYOU5!', database='sephora_cosmetics')\n",
    "cursor = cnx.cursor()\n",
    "\n",
    "#query reviews by product1\n",
    "query = (\"SELECT R.product_id, review_id, review, reviewer, type \"\n",
    "         \"FROM Reviews as R \"\n",
    "         \"JOIN Product as P \"\n",
    "         \"ON P.product_id = R.product_id \")\n",
    "cursor.execute(query)\n",
    "\n",
    "\n",
    "#close mysql server\n",
    "cnx.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#clean reviews data\n",
    "product_id = []\n",
    "review_id = []\n",
    "reviews = []\n",
    "reviewers = []\n",
    "types = []\n",
    "for (x, y, z, w, v) in cursor:\n",
    "    product_id.append(int(x))\n",
    "    review_id.append(int(y))\n",
    "    reviews.append(z)\n",
    "    reviewers.append(w)\n",
    "    types.append(v)\n",
    "\n",
    "#convert to data frame\n",
    "data = list(zip(product_id, review_id, reviews, reviewers, types))\n",
    "review_data = pd.DataFrame(data=data, index=range(0,len(reviews)), columns=['product_id', 'review_id', 'reviews', 'reviewers', 'types'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get training set review ids\n",
    "training = TrainTest()\n",
    "ttset = training.getSet()\n",
    "train = ttset['train']\n",
    "\n",
    "#create training set\n",
    "review_train = review_data.loc[review_data['review_id'].isin(train)]\n",
    "\n",
    "#convert series to lists\n",
    "reviews = review_train['reviews'].tolist()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#tokenizer function\n",
    "def stemTokenizer(text):\n",
    "    #set stop words \n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.update(['.', ',', '\"', \"'\", '?', '!', ':', ';', '(', ')', '[', ']', '{', '}']) # remove it if you need punctuation \n",
    "    tokens = [word.lower() for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent) if word not in stop_words]\n",
    "    \n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    filtered_tokens = [token for token in tokens if re.search('[a-zA-Z]', token)]     \n",
    "            \n",
    "    #stem tokens\n",
    "    sb_stemmer = SnowballStemmer(\"english\")\n",
    "    stemmed_tokens = [sb_stemmer.stem(i) for i in filtered_tokens]\n",
    "    \n",
    "    return stemmed_tokens\n",
    "\n",
    "#get tokens\n",
    "stemmed_tokens = [stemTokenizer(x) for x in reviews]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#get sentiment polarity for reviews\n",
    "sentiment = [TextBlob(x).sentiment.polarity for x in reviews]\n",
    "sentiment = [int(x>0) for x in sentiment]\n",
    "sentiment = pd.Series(sentiment, index=review_train.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.5/lib/python3.5/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype float64 was converted to bool by check_pairwise_arrays.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "#create user-item matrix\n",
    "review_train['sentiment'] = sentiment\n",
    "review_pivot = pd.pivot_table(review_train, index='product_id',columns='reviewers',values='sentiment',fill_value=0)\n",
    "\n",
    "#open file \n",
    "fl = open('../../Data/dist_reviews_item.csv', 'w')\n",
    "writer = csv.writer(fl)\n",
    "\n",
    "#get pairwise distances\n",
    "dist = pairwise_distances(review_pivot, metric='jaccard')\n",
    "\n",
    "#save pairwise distances\n",
    "for i in dist:\n",
    "    writer.writerow(i)\n",
    "\n",
    "#close file\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
